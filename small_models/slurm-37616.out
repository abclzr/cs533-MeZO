/var/spool/slurmd/job37616/slurm_script: 4: [: 1: unexpected operator

Ubuntu 22.04.3 LTS5.15.0-86-generic
----------------------------------------------------------------------------
Machine Name:  	rlab6.cs          IP No:     128.6.13.26 2620:0:d60:ac0d::1a
Mon Apr 29 01:45:39 AM EDT 2024	  Uptime:        	      108 days 08:08
----------------------------------------------------------------------------
Processes:     	941               Local/SSH/X2Go/XRDP/VSCODE:	0/0/0/0/0           
HostProxy:     	0                 TMUX/SCREEN/JUPYTER:	0/0/0
Connections:   	26                Load/Total Users:	69/0
Free Memory:   	790Gi of 1.0Ti    Free Swap:     	499Gi of 499Gi
----------------------------------------------------------------------------
CPU Info:      	Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz - 80 cores 
System CPU:    	6.57%             User CPU:      	71.60%
CPU Idle:      	21.70%            IO Wait:       	0.14%
----------------------------------------------------------------------------
Login as:      	zl606             No. of Sessions:	0
Avail.UserDisk:	                  Avail.Freespace:	4433.85 GB
CUDA Driver:   	11.8              CUDA Cores:    	3072
----------------------------------------------------------------------------

13:4: not a valid test operator: (
13:4: not a valid test operator: 525.125.06

=============
== PyTorch ==
=============

NVIDIA Release 23.12 (build 76438008)
PyTorch Version 2.2.0a0+81ea7a4

Container image Copyright (c) 2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

Copyright (c) 2014-2023 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

NOTE: CUDA Forward Compatibility mode ENABLED.
  Using CUDA 12.3 driver version 545.23.08 with kernel driver version 525.125.06.
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

TASK: SNLI
K: 16
Seed: 42
BS: 8
LR: 1e-5
Step: 1000; Eval step: 100
Grid search tag: seed42-bs8-lr1e-5-step1000-evalstep100
Tag: k16-roberta-base-ft
04/29/2024 01:45:46 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False
04/29/2024 01:45:46 - INFO - __main__ -   Training/evaluation parameters DynamicTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
adjust_for_init=False,
array_id=-1,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
binary_classification=False,
change_grad_estimate=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
efficient_zero_order=False,
efficient_zero_order_fp16=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=100,
evaluate_during_training=True,
evaluation_strategy=no,
exclude_embeddings=False,
exclude_first_layers=-1,
exclude_head=False,
f0_scaling=1.0,
fix_layers=0,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
from_linearhead=False,
fsdp=[],
fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
head_tuning=False,
hf_inference_model=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
jit_mode_eval=False,
kernel_formula=sgd,
kernel_gamma=1.0,
kernel_regularization=0.0,
kernel_solver=logistic,
label_names=None,
label_smoothing_factor=0.0,
layer_wise_optim=False,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=False,
load_kernels=None,
local_rank=-1,
log_file=log,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=result/SNLI-roberta-base-prompt-standard-k16-roberta-base-ftseed42-bs8-lr1e-5-step1000-evalstep100/16-42/runs/Apr29_01-45-46_rlab6.cs.rutgers.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lp_early_stopping=False,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=1000,
max_zo_forward_steps=0,
mc_tol=0.1,
metric_for_best_model=None,
model_id=-1,
mp_parameters=,
no_cuda=False,
no_predict=False,
no_reparam=False,
no_train=False,
norm_running_update=False,
num_hvp_vecs=128,
num_prefix=10,
num_train_epochs=3.0,
only_biases=False,
optim=adamw_hf,
optim_args=None,
optimize_acc=False,
optimizer=adam,
optimizer_variant=,
output_dir=result/SNLI-roberta-base-prompt-standard-k16-roberta-base-ftseed42-bs8-lr1e-5-step1000-evalstep100/16-42,
overwrite_kernels=False,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=4,
per_device_train_batch_size=8,
prediction_loss_only=False,
prefix_init_by_real_act=False,
prefix_tuning=False,
prob_as_feature=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
random_model_init=False,
ray_scope=last,
recompute_norms=False,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=None,
run_name=result/SNLI-roberta-base-prompt-standard-k16-roberta-base-ftseed42-bs8-lr1e-5-step1000-evalstep100/16-42,
save_at_last=False,
save_logit=False,
save_logit_dir=None,
save_on_each_node=False,
save_safetensors=False,
save_steps=500,
save_strategy=steps,
save_total_limit=None,
scale_lr_with_samples=False,
scale_norm_by_num_params=False,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
sweep=False,
sync_embedding_layers=False,
tf32=None,
tie_emb=False,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
trainer=standard,
untie_emb=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
use_zo_grad_est=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
zero_order_clip_grad=False,
zero_order_eps=0.001,
zero_order_optim=False,
zero_order_sample=1,
zero_order_sample_scheduler=None,
zero_order_use_trainer_optim=False,
zo_by_layer=False,
zo_variant=None,
)
04/29/2024 01:45:46 - INFO - __main__ -   Task name: snli, number of labels: 3, output mode: classification
04/29/2024 01:45:47 - WARNING - src.models -   By default for RoBERTa models the input embeddings and the output embeddings are NOT tied!!!!
Some weights of RobertaModelForPromptFinetuning were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'roberta.embeddings.position_ids', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
04/29/2024 01:45:50 - INFO - src.dataset -   Label contradiction to word ĠNo (440)
04/29/2024 01:45:50 - INFO - src.dataset -   Label entailment to word ĠYes (3216)
04/29/2024 01:45:50 - INFO - src.dataset -   Label neutral to word ĠMaybe (5359)
04/29/2024 01:45:50 - INFO - src.dataset -   Total num_sample for mode train: 1
04/29/2024 01:45:50 - INFO - src.dataset -   Creating/loading examples from dataset file at data/k-shot-1k-test/SNLI/16-42
04/29/2024 01:45:50 - INFO - src.dataset -   Creating features from dataset file at data/k-shot-1k-test/SNLI/16-42
04/29/2024 01:45:50 - INFO - src.dataset -   Saving features into cached file data/k-shot-1k-test/SNLI/16-42/cached_train_RobertaTokenizerFast-roberta_256_snli [took 0.002 s]
04/29/2024 01:45:50 - INFO - src.dataset -   Label contradiction to word ĠNo (440)
04/29/2024 01:45:50 - INFO - src.dataset -   Label entailment to word ĠYes (3216)
04/29/2024 01:45:50 - INFO - src.dataset -   Label neutral to word ĠMaybe (5359)
04/29/2024 01:45:50 - INFO - src.dataset -   Total num_sample for mode dev: 1
04/29/2024 01:45:50 - INFO - src.dataset -   Creating/loading examples from dataset file at data/k-shot-1k-test/SNLI/16-42
04/29/2024 01:45:50 - INFO - src.dataset -   Creating features from dataset file at data/k-shot-1k-test/SNLI/16-42
04/29/2024 01:45:50 - INFO - src.dataset -   Saving features into cached file data/k-shot-1k-test/SNLI/16-42/cached_dev_RobertaTokenizerFast-roberta_256_snli [took 0.010 s]
04/29/2024 01:45:50 - INFO - src.dataset -   *** Example ***
04/29/2024 01:45:50 - INFO - src.dataset -   guid: dev-95288
04/29/2024 01:45:50 - INFO - src.dataset -   features: OurInputFeatures(input_ids=[0, 250, 909, 2335, 878, 149, 10, 251, 8978, 10615, 116, 50264, 6, 10, 4758, 1974, 19, 10, 1011, 9, 32566, 4, 2], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=None, label=0, mask_pos=[11], label_word_list=None, sfc_input_ids=None, sfc_attention_mask=None, sfc_mask_pos=None)
04/29/2024 01:45:50 - INFO - src.dataset -   text: <s>A black dog running through a long orange tunnel?<mask>, a cat plays with a ball of yarn.</s>
04/29/2024 01:45:50 - INFO - src.dataset -   Label contradiction to word ĠNo (440)
04/29/2024 01:45:50 - INFO - src.dataset -   Label entailment to word ĠYes (3216)
04/29/2024 01:45:50 - INFO - src.dataset -   Label neutral to word ĠMaybe (5359)
04/29/2024 01:45:50 - INFO - src.dataset -   Total num_sample for mode test: 1
04/29/2024 01:45:50 - INFO - src.dataset -   Creating/loading examples from dataset file at data/k-shot-1k-test/SNLI/16-42
04/29/2024 01:45:50 - INFO - src.dataset -   Creating features from dataset file at data/k-shot-1k-test/SNLI/16-42
04/29/2024 01:45:50 - INFO - src.dataset -   Saving features into cached file data/k-shot-1k-test/SNLI/16-42/cached_test_RobertaTokenizerFast-roberta_256_snli [took 0.009 s]
04/29/2024 01:45:50 - INFO - src.dataset -   *** Example ***
04/29/2024 01:45:50 - INFO - src.dataset -   guid: test-7988
04/29/2024 01:45:50 - INFO - src.dataset -   features: OurInputFeatures(input_ids=[0, 250, 24876, 154, 313, 19, 10, 5851, 438, 20093, 6399, 8, 16447, 7387, 9304, 295, 7527, 15, 39, 28391, 5101, 19, 39, 10654, 15, 39, 8040, 116, 50264, 6, 10, 313, 422, 11, 14988, 4, 2], attention_mask=[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], token_type_ids=None, label=0, mask_pos=[28], label_word_list=None, sfc_input_ids=None, sfc_attention_mask=None, sfc_mask_pos=None)
04/29/2024 01:45:50 - INFO - src.dataset -   text: <s>A balding man with a checkered shirt and khaki pants naps on his recliner with his keys on his lap?<mask>, a man run in playground.</s>
/common/home/zl606/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
04/29/2024 01:45:52 - INFO - src.trainer_ours -   ***** Running training *****
04/29/2024 01:45:52 - INFO - src.trainer_ours -     Num examples = 48
04/29/2024 01:45:52 - INFO - src.trainer_ours -     Num Epochs = 167
04/29/2024 01:45:52 - INFO - src.trainer_ours -     Instantaneous batch size per device = 8
04/29/2024 01:45:52 - INFO - src.trainer_ours -     Total train batch size (w. parallel, distributed & accumulation) = 8
04/29/2024 01:45:52 - INFO - src.trainer_ours -     Gradient Accumulation steps = 1
04/29/2024 01:45:52 - INFO - src.trainer_ours -     Total optimization steps = 1000
You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
04/29/2024 01:45:54 - INFO - src.trainer_ours -   {'loss': 1.750967025756836, 'norm': 77.79608154296875, 'learning_rate': 9.9e-06}
04/29/2024 01:45:54 - INFO - src.trainer_ours -   {'loss': 0.8984251022338867, 'norm': 70.09001922607422, 'learning_rate': 9.800000000000001e-06}
04/29/2024 01:45:55 - INFO - src.trainer_ours -   {'loss': 0.28503055572509767, 'norm': 25.0411434173584, 'learning_rate': 9.7e-06}
04/29/2024 01:45:56 - INFO - src.trainer_ours -   {'loss': 0.060418128967285156, 'norm': 12.656691551208496, 'learning_rate': 9.600000000000001e-06}
04/29/2024 01:45:57 - INFO - src.trainer_ours -   {'loss': 0.025902175903320314, 'norm': 0.6325912475585938, 'learning_rate': 9.5e-06}
04/29/2024 01:45:57 - INFO - src.trainer_ours -   {'loss': 0.006712532043457032, 'norm': 0.515688955783844, 'learning_rate': 9.4e-06}
04/29/2024 01:45:58 - INFO - src.trainer_ours -   {'loss': 0.00027828216552734376, 'norm': 0.015311681665480137, 'learning_rate': 9.3e-06}
04/29/2024 01:45:59 - INFO - src.trainer_ours -   {'loss': 4.38690185546875e-06, 'norm': 0.0038251527585089207, 'learning_rate': 9.200000000000002e-06}
04/29/2024 01:46:00 - INFO - src.trainer_ours -   {'loss': 4.634857177734375e-05, 'norm': 0.0017522232374176383, 'learning_rate': 9.100000000000001e-06}
04/29/2024 01:46:00 - INFO - src.trainer_ours -   {'loss': 8.58306884765625e-06, 'norm': 0.044322337955236435, 'learning_rate': 9e-06}
/common/home/zl606/.local/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:411: FutureWarning: DistributedTensorGatherer is deprecated and will be removed in v5 of Transformers.
  warnings.warn(
RobertaConfig {
  "_name_or_path": "roberta-base",
  "architectures": [
    "RobertaForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "finetuning_task": "snli",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1",
    "2": "LABEL_2"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1,
    "LABEL_2": 2
  },
  "layer_norm_eps": 1e-05,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 1,
  "position_embedding_type": "absolute",
  "transformers_version": "4.28.1",
  "type_vocab_size": 1,
  "use_cache": true,
  "vocab_size": 50265
}

  0%|          | 0/12 [00:00<?, ?it/s] 67%|██████▋   | 8/12 [00:00<00:00, 70.98it/s]04/29/2024 01:46:00 - INFO - src.trainer_ours -   {'eval_loss': 2.5344130992889404, 'eval_acc': 0.6458333333333334}
04/29/2024 01:46:01 - INFO - src.trainer_ours -   Best dev result: 0.6458333333333334
04/29/2024 01:46:02 - INFO - src.trainer_ours -   {'loss': 1.52587890625e-06, 'norm': 0.00928846001625061, 'learning_rate': 8.900000000000001e-06}
04/29/2024 01:46:03 - INFO - src.trainer_ours -   {'loss': 3.4332275390625e-06, 'norm': 0.0011608629720285535, 'learning_rate': 8.8e-06}
04/29/2024 01:46:03 - INFO - src.trainer_ours -   {'loss': 7.43865966796875e-06, 'norm': 0.047924067825078964, 'learning_rate': 8.700000000000001e-06}
04/29/2024 01:46:04 - INFO - src.trainer_ours -   {'loss': 1.6021728515625e-05, 'norm': 0.00011615041876211762, 'learning_rate': 8.6e-06}
04/29/2024 01:46:05 - INFO - src.trainer_ours -   {'loss': 1.33514404296875e-06, 'norm': 0.0005037040100432932, 'learning_rate': 8.5e-06}
04/29/2024 01:46:06 - INFO - src.trainer_ours -   {'loss': 1.6021728515625e-05, 'norm': 0.001339519745670259, 'learning_rate': 8.400000000000001e-06}
04/29/2024 01:46:06 - INFO - src.trainer_ours -   {'loss': 5.7220458984375e-07, 'norm': 0.0011817299528047442, 'learning_rate': 8.3e-06}
04/29/2024 01:46:07 - INFO - src.trainer_ours -   {'loss': 2.6702880859375e-06, 'norm': 0.0004371256218291819, 'learning_rate': 8.2e-06}
04/29/2024 01:46:08 - INFO - src.trainer_ours -   {'loss': 1.125335693359375e-05, 'norm': 5.73002289456781e-05, 'learning_rate': 8.1e-06}
04/29/2024 01:46:08 - INFO - src.trainer_ours -   {'loss': 7.62939453125e-07, 'norm': 0.00016782792226877064, 'learning_rate': 8.000000000000001e-06}
16it [00:08,  1.69it/s]                       04/29/2024 01:46:08 - INFO - src.trainer_ours -   {'eval_loss': 2.502542495727539, 'eval_acc': 0.6875}
04/29/2024 01:46:08 - INFO - src.trainer_ours -   Best dev result: 0.6875
04/29/2024 01:46:10 - INFO - src.trainer_ours -   {'loss': 5.970001220703125e-05, 'norm': 0.0004266361356712878, 'learning_rate': 7.9e-06}
04/29/2024 01:46:10 - INFO - src.trainer_ours -   {'loss': 4.00543212890625e-06, 'norm': 0.004081009421497583, 'learning_rate': 7.800000000000002e-06}
04/29/2024 01:46:11 - INFO - src.trainer_ours -   {'loss': 0.0009931564331054688, 'norm': 0.0005535034579224885, 'learning_rate': 7.7e-06}
04/29/2024 01:46:12 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.0011832925956696272, 'learning_rate': 7.600000000000001e-06}
04/29/2024 01:46:13 - INFO - src.trainer_ours -   {'loss': 7.62939453125e-07, 'norm': 0.0001526612468296662, 'learning_rate': 7.500000000000001e-06}
04/29/2024 01:46:13 - INFO - src.trainer_ours -   {'loss': 9.88006591796875e-05, 'norm': 0.007903069257736206, 'learning_rate': 7.4e-06}
04/29/2024 01:46:14 - INFO - src.trainer_ours -   {'loss': 1.52587890625e-06, 'norm': 8.221290772780776e-05, 'learning_rate': 7.3e-06}
04/29/2024 01:46:15 - INFO - src.trainer_ours -   {'loss': 0.00012073516845703124, 'norm': 0.00012648793926928192, 'learning_rate': 7.2000000000000005e-06}
04/29/2024 01:46:16 - INFO - src.trainer_ours -   {'loss': 6.4849853515625e-06, 'norm': 0.0001907284022308886, 'learning_rate': 7.100000000000001e-06}
04/29/2024 01:46:16 - INFO - src.trainer_ours -   {'loss': 7.62939453125e-07, 'norm': 0.0003169240662828088, 'learning_rate': 7e-06}
25it [00:15,  1.37it/s]04/29/2024 01:46:16 - INFO - src.trainer_ours -   {'eval_loss': 2.7652885913848877, 'eval_acc': 0.6875}
04/29/2024 01:46:17 - INFO - src.trainer_ours -   {'loss': 5.340576171875e-06, 'norm': 5.016461363993585e-05, 'learning_rate': 6.9e-06}
04/29/2024 01:46:18 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 5.359249553293921e-05, 'learning_rate': 6.800000000000001e-06}
04/29/2024 01:46:19 - INFO - src.trainer_ours -   {'loss': 9.136199951171875e-05, 'norm': 1.863966645032633e-05, 'learning_rate': 6.700000000000001e-06}
04/29/2024 01:46:19 - INFO - src.trainer_ours -   {'loss': 1.33514404296875e-06, 'norm': 0.0009698721114546061, 'learning_rate': 6.600000000000001e-06}
04/29/2024 01:46:20 - INFO - src.trainer_ours -   {'loss': 1.621246337890625e-05, 'norm': 0.18454015254974365, 'learning_rate': 6.5000000000000004e-06}
04/29/2024 01:46:21 - INFO - src.trainer_ours -   {'loss': 1.678466796875e-05, 'norm': 0.0012040921719744802, 'learning_rate': 6.4000000000000006e-06}
04/29/2024 01:46:22 - INFO - src.trainer_ours -   {'loss': 1.316070556640625e-05, 'norm': 0.0011337266769260168, 'learning_rate': 6.300000000000001e-06}
04/29/2024 01:46:22 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 2.2310168787953444e-05, 'learning_rate': 6.200000000000001e-06}
04/29/2024 01:46:23 - INFO - src.trainer_ours -   {'loss': 4.38690185546875e-06, 'norm': 5.152537414687686e-05, 'learning_rate': 6.1e-06}
04/29/2024 01:46:24 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.0004407313244882971, 'learning_rate': 6e-06}
37it [00:23,  1.48it/s]46it [00:23,  2.22it/s]04/29/2024 01:46:24 - INFO - src.trainer_ours -   {'eval_loss': 2.9696671962738037, 'eval_acc': 0.6666666666666666}
04/29/2024 01:46:25 - INFO - src.trainer_ours -   {'loss': 5.7220458984375e-07, 'norm': 6.854620005469769e-05, 'learning_rate': 5.9e-06}
04/29/2024 01:46:25 - INFO - src.trainer_ours -   {'loss': 1.33514404296875e-06, 'norm': 4.8128043999895453e-05, 'learning_rate': 5.8e-06}
04/29/2024 01:46:26 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 7.445442315656692e-05, 'learning_rate': 5.7e-06}
04/29/2024 01:46:27 - INFO - src.trainer_ours -   {'loss': 5.7220458984375e-07, 'norm': 1.3919716366217472e-05, 'learning_rate': 5.600000000000001e-06}
04/29/2024 01:46:28 - INFO - src.trainer_ours -   {'loss': 1.52587890625e-06, 'norm': 2.4095805201795883e-05, 'learning_rate': 5.500000000000001e-06}
04/29/2024 01:46:28 - INFO - src.trainer_ours -   {'loss': 5.7220458984375e-07, 'norm': 3.9051730709616095e-05, 'learning_rate': 5.400000000000001e-06}
04/29/2024 01:46:29 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 4.390457252156921e-05, 'learning_rate': 5.300000000000001e-06}
04/29/2024 01:46:30 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.00015068349603097886, 'learning_rate': 5.2e-06}
04/29/2024 01:46:30 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 6.927815411472693e-05, 'learning_rate': 5.1e-06}
04/29/2024 01:46:31 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 5.1038940000580624e-05, 'learning_rate': 5e-06}
50it [00:30,  1.43it/s]60it [00:31,  2.31it/s]04/29/2024 01:46:31 - INFO - src.trainer_ours -   {'eval_loss': 2.9693291187286377, 'eval_acc': 0.6666666666666666}
04/29/2024 01:46:32 - INFO - src.trainer_ours -   {'loss': 1.52587890625e-06, 'norm': 5.111547216074541e-05, 'learning_rate': 4.9000000000000005e-06}
04/29/2024 01:46:33 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 0.0007541400846093893, 'learning_rate': 4.800000000000001e-06}
04/29/2024 01:46:34 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.0002596573031041771, 'learning_rate': 4.7e-06}
04/29/2024 01:46:34 - INFO - src.trainer_ours -   {'loss': 7.62939453125e-07, 'norm': 0.008733607828617096, 'learning_rate': 4.600000000000001e-06}
04/29/2024 01:46:35 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 2.986684557981789e-05, 'learning_rate': 4.5e-06}
04/29/2024 01:46:36 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.00015041195729281753, 'learning_rate': 4.4e-06}
04/29/2024 01:46:37 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 5.124030849401606e-06, 'learning_rate': 4.3e-06}
04/29/2024 01:46:37 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.00027527319616638124, 'learning_rate': 4.2000000000000004e-06}
04/29/2024 01:46:38 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.003965608309954405, 'learning_rate': 4.1e-06}
04/29/2024 01:46:39 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.001210106536746025, 'learning_rate': 4.000000000000001e-06}
65it [00:38,  1.52it/s]04/29/2024 01:46:39 - INFO - src.trainer_ours -   {'eval_loss': 2.9814140796661377, 'eval_acc': 0.6666666666666666}
04/29/2024 01:46:40 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 3.2754443964222446e-05, 'learning_rate': 3.900000000000001e-06}
04/29/2024 01:46:40 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.00019185822748113424, 'learning_rate': 3.8000000000000005e-06}
04/29/2024 01:46:41 - INFO - src.trainer_ours -   {'loss': 4.57763671875e-06, 'norm': 0.0008009190205484629, 'learning_rate': 3.7e-06}
04/29/2024 01:46:42 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.00013985438272356987, 'learning_rate': 3.6000000000000003e-06}
04/29/2024 01:46:42 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 5.971812424832024e-05, 'learning_rate': 3.5e-06}
04/29/2024 01:46:43 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 1.748478098306805e-05, 'learning_rate': 3.4000000000000005e-06}
04/29/2024 01:46:44 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 2.991762085002847e-05, 'learning_rate': 3.3000000000000006e-06}
04/29/2024 01:46:44 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 7.715683750575408e-06, 'learning_rate': 3.2000000000000003e-06}
04/29/2024 01:46:45 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 0.00030853532371111214, 'learning_rate': 3.1000000000000004e-06}
04/29/2024 01:46:46 - INFO - src.trainer_ours -   {'loss': 8.20159912109375e-06, 'norm': 0.00023749274259898812, 'learning_rate': 3e-06}
73it [00:45,  1.36it/s]83it [00:45,  2.15it/s]04/29/2024 01:46:46 - INFO - src.trainer_ours -   {'eval_loss': 3.02557110786438, 'eval_acc': 0.6875}
04/29/2024 01:46:47 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.00011344803351676092, 'learning_rate': 2.9e-06}
04/29/2024 01:46:47 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 4.1292769310530275e-05, 'learning_rate': 2.8000000000000003e-06}
04/29/2024 01:46:48 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 2.976100040541496e-05, 'learning_rate': 2.7000000000000004e-06}
04/29/2024 01:46:49 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 3.0690545827383175e-05, 'learning_rate': 2.6e-06}
04/29/2024 01:46:50 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 9.471216617384925e-05, 'learning_rate': 2.5e-06}
04/29/2024 01:46:50 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.0003076574648730457, 'learning_rate': 2.4000000000000003e-06}
04/29/2024 01:46:51 - INFO - src.trainer_ours -   {'loss': 4.9591064453125e-06, 'norm': 0.0004985626437701285, 'learning_rate': 2.3000000000000004e-06}
04/29/2024 01:46:52 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.0008688378729857504, 'learning_rate': 2.2e-06}
04/29/2024 01:46:52 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 1.4099340660322923e-05, 'learning_rate': 2.1000000000000002e-06}
04/29/2024 01:46:53 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 0.0001496685144957155, 'learning_rate': 2.0000000000000003e-06}
88it [00:52,  1.50it/s]04/29/2024 01:46:53 - INFO - src.trainer_ours -   {'eval_loss': 3.0494778156280518, 'eval_acc': 0.7083333333333334}
04/29/2024 01:46:53 - INFO - src.trainer_ours -   Best dev result: 0.7083333333333334
04/29/2024 01:46:54 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 2.9885140975238755e-05, 'learning_rate': 1.9000000000000002e-06}
04/29/2024 01:46:55 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 3.7546884414041415e-05, 'learning_rate': 1.8000000000000001e-06}
04/29/2024 01:46:56 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 4.488456852413947e-06, 'learning_rate': 1.7000000000000002e-06}
04/29/2024 01:46:56 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 5.243760369921802e-06, 'learning_rate': 1.6000000000000001e-06}
04/29/2024 01:46:57 - INFO - src.trainer_ours -   {'loss': 5.7220458984375e-07, 'norm': 0.0009839048143476248, 'learning_rate': 1.5e-06}
04/29/2024 01:46:58 - INFO - src.trainer_ours -   {'loss': 1.52587890625e-06, 'norm': 0.0001483798841945827, 'learning_rate': 1.4000000000000001e-06}
04/29/2024 01:46:59 - INFO - src.trainer_ours -   {'loss': 9.5367431640625e-07, 'norm': 0.0012765148421749473, 'learning_rate': 1.3e-06}
04/29/2024 01:46:59 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.0002589368377812207, 'learning_rate': 1.2000000000000002e-06}
04/29/2024 01:47:00 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 2.1792289771838114e-05, 'learning_rate': 1.1e-06}
04/29/2024 01:47:01 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 1.8007633116212673e-05, 'learning_rate': 1.0000000000000002e-06}
97it [01:00,  1.37it/s]108it [01:00,  2.18it/s]04/29/2024 01:47:01 - INFO - src.trainer_ours -   {'eval_loss': 3.0501296520233154, 'eval_acc': 0.7083333333333334}
04/29/2024 01:47:02 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 0.0011307494714856148, 'learning_rate': 9.000000000000001e-07}
04/29/2024 01:47:02 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 6.091511022532359e-05, 'learning_rate': 8.000000000000001e-07}
04/29/2024 01:47:03 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 5.9292680816724896e-05, 'learning_rate': 7.000000000000001e-07}
04/29/2024 01:47:04 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 5.240180325927213e-05, 'learning_rate': 6.000000000000001e-07}
04/29/2024 01:47:05 - INFO - src.trainer_ours -   {'loss': 3.814697265625e-07, 'norm': 0.00027185154613107443, 'learning_rate': 5.000000000000001e-07}
04/29/2024 01:47:05 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 3.6660596379078925e-05, 'learning_rate': 4.0000000000000003e-07}
04/29/2024 01:47:06 - INFO - src.trainer_ours -   {'loss': 0.0, 'norm': 0.0002788302081171423, 'learning_rate': 3.0000000000000004e-07}
04/29/2024 01:47:07 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 0.00017806187679525465, 'learning_rate': 2.0000000000000002e-07}
04/29/2024 01:47:08 - INFO - src.trainer_ours -   {'loss': 1.9073486328125e-07, 'norm': 1.2595202861120924e-05, 'learning_rate': 1.0000000000000001e-07}
04/29/2024 01:47:08 - INFO - src.trainer_ours -   {'loss': 5.7220458984375e-07, 'norm': 3.6613673728425056e-05, 'learning_rate': 0.0}
113it [01:08,  1.51it/s]04/29/2024 01:47:08 - INFO - src.trainer_ours -   {'eval_loss': 3.0487754344940186, 'eval_acc': 0.7083333333333334}
04/29/2024 01:47:08 - INFO - src.trainer_ours -   

Training completed. Do not forget to share your model on huggingface.co/models =)


04/29/2024 01:47:09 - INFO - __main__ -   *** Validate ***
121it [01:08,  2.06it/s]129it [01:08,  2.94it/s]04/29/2024 01:47:09 - INFO - src.trainer_ours -   {'eval_loss': 3.0494778156280518, 'eval_acc': 0.7083333333333334}
04/29/2024 01:47:09 - INFO - __main__ -   ***** Eval results snli *****
04/29/2024 01:47:09 - INFO - __main__ -     eval_loss = 3.0494778156280518
04/29/2024 01:47:09 - INFO - __main__ -     eval_acc = 0.7083333333333334
04/29/2024 01:47:09 - INFO - root -   *** Test ***
139it [01:08,  4.48it/s]149it [01:09,  6.59it/s]158it [01:09,  9.13it/s]167it [01:09, 12.49it/s]175it [01:09, 15.97it/s]183it [01:09, 20.61it/s]192it [01:09, 27.07it/s]203it [01:09, 36.57it/s]213it [01:09, 45.54it/s]222it [01:09, 52.85it/s]231it [01:10, 58.94it/s]240it [01:10, 64.32it/s]250it [01:10, 71.64it/s]260it [01:10, 77.60it/s]270it [01:10, 82.43it/s]280it [01:10, 84.79it/s]290it [01:10, 86.75it/s]300it [01:10, 89.40it/s]310it [01:10, 89.25it/s]320it [01:11, 88.10it/s]329it [01:11, 79.18it/s]338it [01:11, 80.70it/s]347it [01:11, 82.33it/s]356it [01:11, 81.50it/s]365it [01:11, 82.37it/s]375it [01:11, 86.46it/s]04/29/2024 01:47:12 - INFO - src.trainer_ours -   {'eval_loss': 3.216336250305176, 'eval_acc': 0.622}
04/29/2024 01:47:12 - INFO - __main__ -   ***** Test results snli *****
04/29/2024 01:47:12 - INFO - __main__ -     eval_loss = 3.216336250305176
04/29/2024 01:47:12 - INFO - __main__ -     eval_acc = 0.622
04/29/2024 01:47:12 - INFO - __main__ -   ****** Output Dir *******
04/29/2024 01:47:12 - INFO - __main__ -   result/SNLI-roberta-base-prompt-standard-k16-roberta-base-ftseed42-bs8-lr1e-5-step1000-evalstep100/16-42
382it [01:11,  5.32it/s]
